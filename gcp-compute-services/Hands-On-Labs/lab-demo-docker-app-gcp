Of course\! Here is a complete, step-by-step guide to creating a Docker demo on Google Cloud Platform (GCP).

This demo will walk you through:

1.  **Creating a simple Python Flask web application.**
2.  **Writing a `Dockerfile` to containerize the application.**
3.  **Building the Docker image.**
4.  **Pushing the image to Google Artifact Registry (GCP's container registry).**
5.  **Deploying and running the container on a Google Compute Engine (GCE) virtual machine.**
6.  **(Bonus)** Deploying the same image to Google Cloud Run for a serverless experience.

All steps can be performed directly in the GCP browser-based Cloud Shell, so you don't need to install any software on your local machine.

-----

### Prerequisites

  * A **Google Cloud Platform Account** with billing enabled. New users get a generous free tier and free credits.
  * A **GCP Project**. If you don't have one, create one from the GCP Console.

-----

### üöÄ Step 1: Set Up Your GCP Environment

First, we'll open the Cloud Shell and enable the necessary APIs.

1.  **Open the GCP Console:** Go to [https://console.cloud.google.com/](https://console.cloud.google.com/).

2.  **Select your project** from the project drop-down list at the top of the page.

3.  **Activate Cloud Shell:** Click the "Activate Cloud Shell" icon ( `>_` ) in the top-right corner of the console. This will open a terminal at the bottom of your browser with `gcloud` CLI and Docker pre-installed and authenticated.

4.  **Set your Project ID and Region** in environment variables for convenience. Replace `[YOUR_PROJECT_ID]` with your actual GCP Project ID.

    ```bash
    export PROJECT_ID=[YOUR_PROJECT_ID]
    export REGION=us-central1 # You can choose a region closer to you
    gcloud config set project $PROJECT_ID
    gcloud config set compute/region $REGION
    ```

5.  **Enable Necessary APIs:** This is a crucial step. These commands allow your project to use Artifact Registry and Compute Engine.

    ```bash
    gcloud services enable artifactregistry.googleapis.com
    gcloud services enable compute.googleapis.com
    gcloud services enable run.googleapis.com # For the bonus step
    ```

-----

### üêç Step 2: Create a Simple Python Web Application

In your Cloud Shell terminal, we'll create the files for our application.

1.  **Create a project directory:**

    ```bash
    mkdir gcp-docker-demo
    cd gcp-docker-demo
    ```

2.  **Create the Python application file (`app.py`):** This is a simple web server that will respond with a message.

    ```bash
    cat <<EOF > app.py
    from flask import Flask
    import os

    app = Flask(__name__)

    @app.route('/')
    def hello_world():
        return 'Hello from a Docker container running on Google Cloud!'

    if __name__ == "__main__":
        app.run(debug=True, host='0.0.0.0', port=int(os.environ.get('PORT', 8080)))
    EOF
    ```

    *Note: We use `host='0.0.0.0'` to make the server accessible from outside the container.*

3.  **Create a `requirements.txt` file:** This file lists the Python libraries our app needs. We'll use Gunicorn as it's a production-ready web server.

    ```bash
    cat <<EOF > requirements.txt
    Flask==2.2.2
    gunicorn==20.1.0
    EOF
    ```

You now have a complete, simple web application ready to be containerized.

-----

### üê≥ Step 3: Create the Dockerfile

The `Dockerfile` is a script that contains instructions for building our Docker image.

1.  **Create the `Dockerfile` in the same directory:**

    ```bash
    cat <<EOF > Dockerfile
    # Use an official lightweight Python image
    FROM python:3.9-slim

    # Set the working directory inside the container
    WORKDIR /app

    # Copy the requirements file into the container
    COPY requirements.txt .

    # Install the Python dependencies
    RUN pip install --no-cache-dir -r requirements.txt

    # Copy the rest of the application code into the container
    COPY . .

    # Expose the port the app runs on
    EXPOSE 8080

    # Command to run the application using gunicorn
    CMD ["gunicorn", "--bind", "0.0.0.0:8080", "app:app"]
    EOF
    ```

-----

### ‚òÅÔ∏è Step 4: Build and Push the Image to Artifact Registry

Now we'll build the Docker image and store it in GCP's private Artifact Registry.

1.  **Create an Artifact Registry repository:** This is where your Docker images will be stored.

    ```bash
    gcloud artifacts repositories create my-docker-repo \
        --repository-format=docker \
        --location=$REGION \
        --description="Docker repository for demo"
    ```

2.  **Configure Docker to authenticate with Artifact Registry:** This command configures the Docker client to use your GCP credentials.

    ```bash
    gcloud auth configure-docker ${REGION}-docker.pkg.dev
    ```

3.  **Build the Docker image:** We will tag the image with its future location in Artifact Registry.

    ```bash
    export IMAGE_TAG="${REGION}-docker.pkg.dev/${PROJECT_ID}/my-docker-repo/hello-gcp-app:v1"
    docker build -t $IMAGE_TAG .
    ```

    You will see Docker running through the steps in your `Dockerfile`.

4.  **Push the image to Artifact Registry:**

    ```bash
    docker push $IMAGE_TAG
    ```

    After this completes, your container image is securely stored in GCP and ready to be deployed.

-----

### üñ•Ô∏è Step 5: Deploy the Container on a Compute Engine VM

This method demonstrates running your container on a traditional virtual machine.

1.  **Create a Compute Engine VM instance that automatically runs your container:**
    The `create-with-container` command is a powerful shortcut that creates a VM, installs Docker, and runs your specified container image.

    ```bash
    gcloud compute instances create-with-container gcp-docker-vm \
        --machine-type=e2-micro \
        --zone=${REGION}-c \
        --tags=http-server \
        --container-image=$IMAGE_TAG
    ```

      * `--tags=http-server`: We add a network tag to this VM, which we'll use in the next step for a firewall rule.

2.  **Create a firewall rule to allow traffic:** By default, traffic from the internet is blocked. This rule allows HTTP traffic on port `8080` to any VM with the `http-server` tag.

    ```bash
    gcloud compute firewall-rules create allow-http-8080 \
        --allow tcp:8080 \
        --target-tags=http-server \
        --description="Allow port 8080 for http-server"
    ```

3.  **Get the External IP of your VM and test it:**

    ```bash
    gcloud compute instances list
    ```

    Find the `EXTERNAL_IP` for your `gcp-docker-vm` instance in the output.

4.  **Visit the URL:** Open your web browser and navigate to:
    `http://[YOUR_VM_EXTERNAL_IP]:8080`

    You should see the message: **Hello from a Docker container running on Google Cloud\!**

-----

### ‚ú® Bonus Step: Deploy the Same Image to Cloud Run (Serverless)

Cloud Run is often an easier, more cost-effective way to run web containers. It's fully managed and scales to zero (you pay nothing if it's not being used).

1.  **Deploy the image from Artifact Registry to Cloud Run:**

    ```bash
    gcloud run deploy hello-gcp-service \
        --image=$IMAGE_TAG \
        --platform=managed \
        --region=$REGION \
        --allow-unauthenticated
    ```

      * `--allow-unauthenticated`: This makes your service public.
      * You will be prompted to confirm the service name. Press **Enter**.

2.  **Test the Cloud Run service:** After the command finishes, it will output a **Service URL**. Click on this URL.

    You will see the same message, but this time it's served by a fully managed, serverless platform with automatic HTTPS\!

-----

### üßπ Step 6: Clean Up

To avoid incurring future charges, delete the resources you created.

```bash
# Delete the Compute Engine VM
gcloud compute instances delete gcp-docker-vm --zone=${REGION}-c --quiet

# Delete the firewall rule
gcloud compute firewall-rules delete allow-http-8080 --quiet

# Delete the Cloud Run service
gcloud run services delete hello-gcp-service --platform=managed --region=$REGION --quiet

# Delete the Artifact Registry repository (use with caution if you have other images)
gcloud artifacts repositories delete my-docker-repo --location=$REGION --quiet

# Optional: Delete the container image artifacts from storage
# This is a bit more advanced but ensures complete cleanup of the image layers
gcloud artifacts packages delete hello-gcp-app --repository=my-docker-repo --location=$REGION --quiet
```

You have now successfully created, containerized, and deployed a web application on Google Cloud using Docker\!
